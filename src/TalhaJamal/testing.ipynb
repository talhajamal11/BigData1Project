{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import openpyxl\n",
    "import scipy.optimize as minimizer \n",
    "import seaborn as sns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from files\n",
    "os.chdir('/Users/talhajamal/Desktop/Code/BigData1Project')\n",
    "data = pd.read_csv(\"data/Returns_Data.csv\")\n",
    "data['date'] = pd.to_datetime(data['date'], dayfirst=False)\n",
    "characteristics = pd.read_csv(\"data/Stock_Characteristics_Data.csv\")\n",
    "dictionary = pd.read_excel(\"data/StockDataDictionary.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframes\n",
    "prices = data.pivot(index='date', columns='ticker', values='PRC')\n",
    "volume = data.pivot(index='date', columns='ticker', values='VOL')\n",
    "returns = data.pivot(index='date', columns='ticker', values='RET')\n",
    "returns = returns * 100 # Scale returns to percentage\n",
    "# Summary of Returns\n",
    "returns_summary = returns.describe()\n",
    "shares_outstanding = data.pivot(index='date', columns='ticker', values='SHROUT')\n",
    "value_weighted_returns = data.pivot(index='date', columns='ticker', values='vwretd')\n",
    "equal_weighted_returns = data.pivot(index='date', columns='ticker', values='ewretd')\n",
    "tickers = prices.columns # List of Tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AFL</th>\n",
       "      <th>AIZ</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>AMP</th>\n",
       "      <th>APH</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BBY</th>\n",
       "      <th>...</th>\n",
       "      <th>TRV</th>\n",
       "      <th>TSN</th>\n",
       "      <th>UNM</th>\n",
       "      <th>VFC</th>\n",
       "      <th>VLO</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WAT</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>0.2850</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>1.0232</td>\n",
       "      <td>2.8541</td>\n",
       "      <td>2.3066</td>\n",
       "      <td>2.5825</td>\n",
       "      <td>2.7306</td>\n",
       "      <td>-0.5197</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>1.8500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.1003</td>\n",
       "      <td>-0.2445</td>\n",
       "      <td>2.1516</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>6.8060</td>\n",
       "      <td>0.4528</td>\n",
       "      <td>-0.5326</td>\n",
       "      <td>2.6426</td>\n",
       "      <td>9.8403</td>\n",
       "      <td>1.4078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>0.1271</td>\n",
       "      <td>-0.5136</td>\n",
       "      <td>-0.4961</td>\n",
       "      <td>5.7551</td>\n",
       "      <td>5.2907</td>\n",
       "      <td>1.8133</td>\n",
       "      <td>5.0626</td>\n",
       "      <td>-2.6094</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>4.3879</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.4693</td>\n",
       "      <td>1.6346</td>\n",
       "      <td>3.6060</td>\n",
       "      <td>2.0991</td>\n",
       "      <td>9.3773</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>-1.8956</td>\n",
       "      <td>4.7655</td>\n",
       "      <td>15.9222</td>\n",
       "      <td>1.7983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>-0.0627</td>\n",
       "      <td>-0.7483</td>\n",
       "      <td>-0.2588</td>\n",
       "      <td>6.6335</td>\n",
       "      <td>5.0009</td>\n",
       "      <td>1.6019</td>\n",
       "      <td>6.4593</td>\n",
       "      <td>-2.2314</td>\n",
       "      <td>2.3838</td>\n",
       "      <td>3.6114</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.8882</td>\n",
       "      <td>6.6867</td>\n",
       "      <td>4.4958</td>\n",
       "      <td>1.6979</td>\n",
       "      <td>11.8841</td>\n",
       "      <td>-2.2013</td>\n",
       "      <td>-1.7146</td>\n",
       "      <td>3.6598</td>\n",
       "      <td>14.6105</td>\n",
       "      <td>2.6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>-0.8548</td>\n",
       "      <td>-0.7954</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>7.7068</td>\n",
       "      <td>6.2279</td>\n",
       "      <td>0.5426</td>\n",
       "      <td>7.2084</td>\n",
       "      <td>-2.8959</td>\n",
       "      <td>3.9986</td>\n",
       "      <td>5.2010</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.4489</td>\n",
       "      <td>8.4424</td>\n",
       "      <td>6.7006</td>\n",
       "      <td>3.6313</td>\n",
       "      <td>12.6284</td>\n",
       "      <td>-2.7965</td>\n",
       "      <td>-1.2877</td>\n",
       "      <td>3.2126</td>\n",
       "      <td>16.7461</td>\n",
       "      <td>2.3484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>-0.2799</td>\n",
       "      <td>-0.9366</td>\n",
       "      <td>3.3549</td>\n",
       "      <td>6.7050</td>\n",
       "      <td>6.2917</td>\n",
       "      <td>4.4113</td>\n",
       "      <td>7.5682</td>\n",
       "      <td>-2.1601</td>\n",
       "      <td>3.9271</td>\n",
       "      <td>1.2771</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.5928</td>\n",
       "      <td>8.2173</td>\n",
       "      <td>5.3583</td>\n",
       "      <td>3.1044</td>\n",
       "      <td>11.2564</td>\n",
       "      <td>-2.7335</td>\n",
       "      <td>-1.2059</td>\n",
       "      <td>2.2917</td>\n",
       "      <td>16.0296</td>\n",
       "      <td>1.9472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>225.2769</td>\n",
       "      <td>209.1564</td>\n",
       "      <td>318.5352</td>\n",
       "      <td>134.8974</td>\n",
       "      <td>210.7661</td>\n",
       "      <td>266.2223</td>\n",
       "      <td>249.6355</td>\n",
       "      <td>215.6821</td>\n",
       "      <td>168.8371</td>\n",
       "      <td>215.7204</td>\n",
       "      <td>...</td>\n",
       "      <td>157.3226</td>\n",
       "      <td>228.5158</td>\n",
       "      <td>105.6305</td>\n",
       "      <td>230.4820</td>\n",
       "      <td>248.2550</td>\n",
       "      <td>132.9342</td>\n",
       "      <td>175.7468</td>\n",
       "      <td>164.4529</td>\n",
       "      <td>229.2066</td>\n",
       "      <td>21.8604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>225.4223</td>\n",
       "      <td>209.1847</td>\n",
       "      <td>317.9579</td>\n",
       "      <td>135.0799</td>\n",
       "      <td>211.3392</td>\n",
       "      <td>265.6832</td>\n",
       "      <td>249.7831</td>\n",
       "      <td>216.2008</td>\n",
       "      <td>169.6978</td>\n",
       "      <td>215.7497</td>\n",
       "      <td>...</td>\n",
       "      <td>157.8280</td>\n",
       "      <td>227.8830</td>\n",
       "      <td>106.4060</td>\n",
       "      <td>232.3294</td>\n",
       "      <td>247.1954</td>\n",
       "      <td>133.1721</td>\n",
       "      <td>175.7266</td>\n",
       "      <td>164.0393</td>\n",
       "      <td>230.1507</td>\n",
       "      <td>22.1969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>224.7173</td>\n",
       "      <td>208.1995</td>\n",
       "      <td>317.4440</td>\n",
       "      <td>134.6928</td>\n",
       "      <td>210.7019</td>\n",
       "      <td>264.9762</td>\n",
       "      <td>249.3041</td>\n",
       "      <td>215.1226</td>\n",
       "      <td>169.5119</td>\n",
       "      <td>213.9755</td>\n",
       "      <td>...</td>\n",
       "      <td>157.2245</td>\n",
       "      <td>226.5161</td>\n",
       "      <td>106.8587</td>\n",
       "      <td>231.5219</td>\n",
       "      <td>247.8489</td>\n",
       "      <td>132.8839</td>\n",
       "      <td>175.2530</td>\n",
       "      <td>162.9120</td>\n",
       "      <td>229.1461</td>\n",
       "      <td>21.0709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>226.4714</td>\n",
       "      <td>207.5933</td>\n",
       "      <td>317.8801</td>\n",
       "      <td>135.2871</td>\n",
       "      <td>211.8337</td>\n",
       "      <td>268.1921</td>\n",
       "      <td>250.5100</td>\n",
       "      <td>216.2126</td>\n",
       "      <td>170.6038</td>\n",
       "      <td>214.5908</td>\n",
       "      <td>...</td>\n",
       "      <td>157.7521</td>\n",
       "      <td>226.6578</td>\n",
       "      <td>107.9853</td>\n",
       "      <td>233.1618</td>\n",
       "      <td>250.1393</td>\n",
       "      <td>131.7446</td>\n",
       "      <td>175.1269</td>\n",
       "      <td>163.8721</td>\n",
       "      <td>228.3500</td>\n",
       "      <td>21.8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>227.5317</td>\n",
       "      <td>208.9684</td>\n",
       "      <td>319.8607</td>\n",
       "      <td>136.3323</td>\n",
       "      <td>213.4677</td>\n",
       "      <td>267.4103</td>\n",
       "      <td>252.0674</td>\n",
       "      <td>216.9289</td>\n",
       "      <td>171.8430</td>\n",
       "      <td>213.0224</td>\n",
       "      <td>...</td>\n",
       "      <td>158.6796</td>\n",
       "      <td>227.9945</td>\n",
       "      <td>110.2135</td>\n",
       "      <td>232.3028</td>\n",
       "      <td>249.8748</td>\n",
       "      <td>132.7938</td>\n",
       "      <td>175.8844</td>\n",
       "      <td>163.5155</td>\n",
       "      <td>227.8474</td>\n",
       "      <td>20.9570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2769 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker           ADI       ADP      ADSK       AFL       AIZ      AMAT  \\\n",
       "date                                                                     \n",
       "2010-01-04    0.2850    0.0234    1.0232    2.8541    2.3066    2.5825   \n",
       "2010-01-05    0.1271   -0.5136   -0.4961    5.7551    5.2907    1.8133   \n",
       "2010-01-06   -0.0627   -0.7483   -0.2588    6.6335    5.0009    1.6019   \n",
       "2010-01-07   -0.8548   -0.7954    0.2937    7.7068    6.2279    0.5426   \n",
       "2010-01-08   -0.2799   -0.9366    3.3549    6.7050    6.2917    4.4113   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2020-12-24  225.2769  209.1564  318.5352  134.8974  210.7661  266.2223   \n",
       "2020-12-28  225.4223  209.1847  317.9579  135.0799  211.3392  265.6832   \n",
       "2020-12-29  224.7173  208.1995  317.4440  134.6928  210.7019  264.9762   \n",
       "2020-12-30  226.4714  207.5933  317.8801  135.2871  211.8337  268.1921   \n",
       "2020-12-31  227.5317  208.9684  319.8607  136.3323  213.4677  267.4103   \n",
       "\n",
       "ticker           AMP       APH       AXP       BBY  ...       TRV       TSN  \\\n",
       "date                                                ...                       \n",
       "2010-01-04    2.7306   -0.5197    0.9872    1.8500  ...   -0.1003   -0.2445   \n",
       "2010-01-05    5.0626   -2.6094    0.7673    4.3879  ...   -2.4693    1.6346   \n",
       "2010-01-06    6.4593   -2.2314    2.3838    3.6114  ...   -3.8882    6.6867   \n",
       "2010-01-07    7.2084   -2.8959    3.9986    5.2010  ...   -2.4489    8.4424   \n",
       "2010-01-08    7.5682   -2.1601    3.9271    1.2771  ...   -2.5928    8.2173   \n",
       "...              ...       ...       ...       ...  ...       ...       ...   \n",
       "2020-12-24  249.6355  215.6821  168.8371  215.7204  ...  157.3226  228.5158   \n",
       "2020-12-28  249.7831  216.2008  169.6978  215.7497  ...  157.8280  227.8830   \n",
       "2020-12-29  249.3041  215.1226  169.5119  213.9755  ...  157.2245  226.5161   \n",
       "2020-12-30  250.5100  216.2126  170.6038  214.5908  ...  157.7521  226.6578   \n",
       "2020-12-31  252.0674  216.9289  171.8430  213.0224  ...  158.6796  227.9945   \n",
       "\n",
       "ticker           UNM       VFC       VLO        VZ       WAT        WY  \\\n",
       "date                                                                     \n",
       "2010-01-04    2.1516    0.1912    6.8060    0.4528   -0.5326    2.6426   \n",
       "2010-01-05    3.6060    2.0991    9.3773    0.6331   -1.8956    4.7655   \n",
       "2010-01-06    4.4958    1.6979   11.8841   -2.2013   -1.7146    3.6598   \n",
       "2010-01-07    6.7006    3.6313   12.6284   -2.7965   -1.2877    3.2126   \n",
       "2010-01-08    5.3583    3.1044   11.2564   -2.7335   -1.2059    2.2917   \n",
       "...              ...       ...       ...       ...       ...       ...   \n",
       "2020-12-24  105.6305  230.4820  248.2550  132.9342  175.7468  164.4529   \n",
       "2020-12-28  106.4060  232.3294  247.1954  133.1721  175.7266  164.0393   \n",
       "2020-12-29  106.8587  231.5219  247.8489  132.8839  175.2530  162.9120   \n",
       "2020-12-30  107.9853  233.1618  250.1393  131.7446  175.1269  163.8721   \n",
       "2020-12-31  110.2135  232.3028  249.8748  132.7938  175.8844  163.5155   \n",
       "\n",
       "ticker          WYNN      XOM  \n",
       "date                           \n",
       "2010-01-04    9.8403   1.4078  \n",
       "2010-01-05   15.9222   1.7983  \n",
       "2010-01-06   14.6105   2.6626  \n",
       "2010-01-07   16.7461   2.3484  \n",
       "2010-01-08   16.0296   1.9472  \n",
       "...              ...      ...  \n",
       "2020-12-24  229.2066  21.8604  \n",
       "2020-12-28  230.1507  22.1969  \n",
       "2020-12-29  229.1461  21.0709  \n",
       "2020-12-30  228.3500  21.8705  \n",
       "2020-12-31  227.8474  20.9570  \n",
       "\n",
       "[2769 rows x 100 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative Returns\n",
    "returns.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AFL</th>\n",
       "      <th>AIZ</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>AMP</th>\n",
       "      <th>APH</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BBY</th>\n",
       "      <th>...</th>\n",
       "      <th>TRV</th>\n",
       "      <th>TSN</th>\n",
       "      <th>UNM</th>\n",
       "      <th>VFC</th>\n",
       "      <th>VLO</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WAT</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADI</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.575610</td>\n",
       "      <td>0.552164</td>\n",
       "      <td>0.523202</td>\n",
       "      <td>0.462259</td>\n",
       "      <td>0.714050</td>\n",
       "      <td>0.596292</td>\n",
       "      <td>0.637304</td>\n",
       "      <td>0.546807</td>\n",
       "      <td>0.347137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483073</td>\n",
       "      <td>0.326923</td>\n",
       "      <td>0.517449</td>\n",
       "      <td>0.465644</td>\n",
       "      <td>0.437207</td>\n",
       "      <td>0.338292</td>\n",
       "      <td>0.495225</td>\n",
       "      <td>0.534595</td>\n",
       "      <td>0.464222</td>\n",
       "      <td>0.506499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>0.575610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.528904</td>\n",
       "      <td>0.605848</td>\n",
       "      <td>0.540483</td>\n",
       "      <td>0.559727</td>\n",
       "      <td>0.655543</td>\n",
       "      <td>0.622024</td>\n",
       "      <td>0.616486</td>\n",
       "      <td>0.355851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.624318</td>\n",
       "      <td>0.363147</td>\n",
       "      <td>0.581940</td>\n",
       "      <td>0.528556</td>\n",
       "      <td>0.489928</td>\n",
       "      <td>0.485502</td>\n",
       "      <td>0.553371</td>\n",
       "      <td>0.597151</td>\n",
       "      <td>0.416860</td>\n",
       "      <td>0.575303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADSK</th>\n",
       "      <td>0.552164</td>\n",
       "      <td>0.528904</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.463746</td>\n",
       "      <td>0.398231</td>\n",
       "      <td>0.552088</td>\n",
       "      <td>0.550950</td>\n",
       "      <td>0.568078</td>\n",
       "      <td>0.474242</td>\n",
       "      <td>0.314827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.401518</td>\n",
       "      <td>0.288148</td>\n",
       "      <td>0.437308</td>\n",
       "      <td>0.434490</td>\n",
       "      <td>0.407097</td>\n",
       "      <td>0.283416</td>\n",
       "      <td>0.484981</td>\n",
       "      <td>0.470147</td>\n",
       "      <td>0.405759</td>\n",
       "      <td>0.404498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFL</th>\n",
       "      <td>0.523202</td>\n",
       "      <td>0.605848</td>\n",
       "      <td>0.463746</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>0.490498</td>\n",
       "      <td>0.711044</td>\n",
       "      <td>0.608352</td>\n",
       "      <td>0.690189</td>\n",
       "      <td>0.346125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637511</td>\n",
       "      <td>0.412584</td>\n",
       "      <td>0.724434</td>\n",
       "      <td>0.548912</td>\n",
       "      <td>0.569525</td>\n",
       "      <td>0.408948</td>\n",
       "      <td>0.501116</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.503274</td>\n",
       "      <td>0.619953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIZ</th>\n",
       "      <td>0.462259</td>\n",
       "      <td>0.540483</td>\n",
       "      <td>0.398231</td>\n",
       "      <td>0.633143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.444370</td>\n",
       "      <td>0.623686</td>\n",
       "      <td>0.526663</td>\n",
       "      <td>0.547776</td>\n",
       "      <td>0.333194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655542</td>\n",
       "      <td>0.345027</td>\n",
       "      <td>0.618616</td>\n",
       "      <td>0.448169</td>\n",
       "      <td>0.448457</td>\n",
       "      <td>0.391155</td>\n",
       "      <td>0.429497</td>\n",
       "      <td>0.504014</td>\n",
       "      <td>0.376574</td>\n",
       "      <td>0.515368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VZ</th>\n",
       "      <td>0.338292</td>\n",
       "      <td>0.485502</td>\n",
       "      <td>0.283416</td>\n",
       "      <td>0.408948</td>\n",
       "      <td>0.391155</td>\n",
       "      <td>0.312622</td>\n",
       "      <td>0.429567</td>\n",
       "      <td>0.400548</td>\n",
       "      <td>0.384200</td>\n",
       "      <td>0.231419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456158</td>\n",
       "      <td>0.290179</td>\n",
       "      <td>0.382645</td>\n",
       "      <td>0.346429</td>\n",
       "      <td>0.310185</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.360842</td>\n",
       "      <td>0.387749</td>\n",
       "      <td>0.228160</td>\n",
       "      <td>0.412483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAT</th>\n",
       "      <td>0.495225</td>\n",
       "      <td>0.553371</td>\n",
       "      <td>0.484981</td>\n",
       "      <td>0.501116</td>\n",
       "      <td>0.429497</td>\n",
       "      <td>0.480138</td>\n",
       "      <td>0.552548</td>\n",
       "      <td>0.573233</td>\n",
       "      <td>0.509605</td>\n",
       "      <td>0.286880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455313</td>\n",
       "      <td>0.281526</td>\n",
       "      <td>0.479949</td>\n",
       "      <td>0.454820</td>\n",
       "      <td>0.426990</td>\n",
       "      <td>0.360842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.502558</td>\n",
       "      <td>0.381953</td>\n",
       "      <td>0.470176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>0.534595</td>\n",
       "      <td>0.597151</td>\n",
       "      <td>0.470147</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.504014</td>\n",
       "      <td>0.506892</td>\n",
       "      <td>0.649698</td>\n",
       "      <td>0.584423</td>\n",
       "      <td>0.608739</td>\n",
       "      <td>0.371413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.570950</td>\n",
       "      <td>0.358299</td>\n",
       "      <td>0.598621</td>\n",
       "      <td>0.524152</td>\n",
       "      <td>0.497598</td>\n",
       "      <td>0.387749</td>\n",
       "      <td>0.502558</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.458862</td>\n",
       "      <td>0.571841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WYNN</th>\n",
       "      <td>0.464222</td>\n",
       "      <td>0.416860</td>\n",
       "      <td>0.405759</td>\n",
       "      <td>0.503274</td>\n",
       "      <td>0.376574</td>\n",
       "      <td>0.454122</td>\n",
       "      <td>0.497309</td>\n",
       "      <td>0.481443</td>\n",
       "      <td>0.522615</td>\n",
       "      <td>0.284438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.417731</td>\n",
       "      <td>0.299607</td>\n",
       "      <td>0.498535</td>\n",
       "      <td>0.438643</td>\n",
       "      <td>0.464208</td>\n",
       "      <td>0.228160</td>\n",
       "      <td>0.381953</td>\n",
       "      <td>0.458862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.484089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>0.506499</td>\n",
       "      <td>0.575303</td>\n",
       "      <td>0.404498</td>\n",
       "      <td>0.619953</td>\n",
       "      <td>0.515368</td>\n",
       "      <td>0.470659</td>\n",
       "      <td>0.622850</td>\n",
       "      <td>0.554113</td>\n",
       "      <td>0.594038</td>\n",
       "      <td>0.312178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.571868</td>\n",
       "      <td>0.367563</td>\n",
       "      <td>0.641441</td>\n",
       "      <td>0.519808</td>\n",
       "      <td>0.613214</td>\n",
       "      <td>0.412483</td>\n",
       "      <td>0.470176</td>\n",
       "      <td>0.571841</td>\n",
       "      <td>0.484089</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker       ADI       ADP      ADSK       AFL       AIZ      AMAT       AMP  \\\n",
       "ticker                                                                         \n",
       "ADI     1.000000  0.575610  0.552164  0.523202  0.462259  0.714050  0.596292   \n",
       "ADP     0.575610  1.000000  0.528904  0.605848  0.540483  0.559727  0.655543   \n",
       "ADSK    0.552164  0.528904  1.000000  0.463746  0.398231  0.552088  0.550950   \n",
       "AFL     0.523202  0.605848  0.463746  1.000000  0.633143  0.490498  0.711044   \n",
       "AIZ     0.462259  0.540483  0.398231  0.633143  1.000000  0.444370  0.623686   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "VZ      0.338292  0.485502  0.283416  0.408948  0.391155  0.312622  0.429567   \n",
       "WAT     0.495225  0.553371  0.484981  0.501116  0.429497  0.480138  0.552548   \n",
       "WY      0.534595  0.597151  0.470147  0.598684  0.504014  0.506892  0.649698   \n",
       "WYNN    0.464222  0.416860  0.405759  0.503274  0.376574  0.454122  0.497309   \n",
       "XOM     0.506499  0.575303  0.404498  0.619953  0.515368  0.470659  0.622850   \n",
       "\n",
       "ticker       APH       AXP       BBY  ...       TRV       TSN       UNM  \\\n",
       "ticker                                ...                                 \n",
       "ADI     0.637304  0.546807  0.347137  ...  0.483073  0.326923  0.517449   \n",
       "ADP     0.622024  0.616486  0.355851  ...  0.624318  0.363147  0.581940   \n",
       "ADSK    0.568078  0.474242  0.314827  ...  0.401518  0.288148  0.437308   \n",
       "AFL     0.608352  0.690189  0.346125  ...  0.637511  0.412584  0.724434   \n",
       "AIZ     0.526663  0.547776  0.333194  ...  0.655542  0.345027  0.618616   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "VZ      0.400548  0.384200  0.231419  ...  0.456158  0.290179  0.382645   \n",
       "WAT     0.573233  0.509605  0.286880  ...  0.455313  0.281526  0.479949   \n",
       "WY      0.584423  0.608739  0.371413  ...  0.570950  0.358299  0.598621   \n",
       "WYNN    0.481443  0.522615  0.284438  ...  0.417731  0.299607  0.498535   \n",
       "XOM     0.554113  0.594038  0.312178  ...  0.571868  0.367563  0.641441   \n",
       "\n",
       "ticker       VFC       VLO        VZ       WAT        WY      WYNN       XOM  \n",
       "ticker                                                                        \n",
       "ADI     0.465644  0.437207  0.338292  0.495225  0.534595  0.464222  0.506499  \n",
       "ADP     0.528556  0.489928  0.485502  0.553371  0.597151  0.416860  0.575303  \n",
       "ADSK    0.434490  0.407097  0.283416  0.484981  0.470147  0.405759  0.404498  \n",
       "AFL     0.548912  0.569525  0.408948  0.501116  0.598684  0.503274  0.619953  \n",
       "AIZ     0.448169  0.448457  0.391155  0.429497  0.504014  0.376574  0.515368  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "VZ      0.346429  0.310185  1.000000  0.360842  0.387749  0.228160  0.412483  \n",
       "WAT     0.454820  0.426990  0.360842  1.000000  0.502558  0.381953  0.470176  \n",
       "WY      0.524152  0.497598  0.387749  0.502558  1.000000  0.458862  0.571841  \n",
       "WYNN    0.438643  0.464208  0.228160  0.381953  0.458862  1.000000  0.484089  \n",
       "XOM     0.519808  0.613214  0.412483  0.470176  0.571841  0.484089  1.000000  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create correlation matrix\n",
    "correlation_matrix = returns.corr()\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AFL</th>\n",
       "      <th>AIZ</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>AMP</th>\n",
       "      <th>APH</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BBY</th>\n",
       "      <th>...</th>\n",
       "      <th>TRV</th>\n",
       "      <th>TSN</th>\n",
       "      <th>UNM</th>\n",
       "      <th>VFC</th>\n",
       "      <th>VLO</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WAT</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADI</th>\n",
       "      <td>3.262099</td>\n",
       "      <td>1.431482</td>\n",
       "      <td>2.258351</td>\n",
       "      <td>1.684421</td>\n",
       "      <td>1.371195</td>\n",
       "      <td>2.754325</td>\n",
       "      <td>2.335061</td>\n",
       "      <td>1.830164</td>\n",
       "      <td>1.806743</td>\n",
       "      <td>1.582277</td>\n",
       "      <td>...</td>\n",
       "      <td>1.230018</td>\n",
       "      <td>1.088972</td>\n",
       "      <td>2.044468</td>\n",
       "      <td>1.533855</td>\n",
       "      <td>1.971979</td>\n",
       "      <td>0.676519</td>\n",
       "      <td>1.468850</td>\n",
       "      <td>1.935924</td>\n",
       "      <td>2.466527</td>\n",
       "      <td>1.371915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADP</th>\n",
       "      <td>1.431482</td>\n",
       "      <td>1.895913</td>\n",
       "      <td>1.649152</td>\n",
       "      <td>1.486982</td>\n",
       "      <td>1.222238</td>\n",
       "      <td>1.645976</td>\n",
       "      <td>1.957046</td>\n",
       "      <td>1.361792</td>\n",
       "      <td>1.552912</td>\n",
       "      <td>1.236547</td>\n",
       "      <td>...</td>\n",
       "      <td>1.211896</td>\n",
       "      <td>0.922177</td>\n",
       "      <td>1.752877</td>\n",
       "      <td>1.327340</td>\n",
       "      <td>1.684646</td>\n",
       "      <td>0.740185</td>\n",
       "      <td>1.251271</td>\n",
       "      <td>1.648574</td>\n",
       "      <td>1.688536</td>\n",
       "      <td>1.187972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADSK</th>\n",
       "      <td>2.258351</td>\n",
       "      <td>1.649152</td>\n",
       "      <td>5.128014</td>\n",
       "      <td>1.871921</td>\n",
       "      <td>1.481065</td>\n",
       "      <td>2.670058</td>\n",
       "      <td>2.705062</td>\n",
       "      <td>2.045397</td>\n",
       "      <td>1.964669</td>\n",
       "      <td>1.799203</td>\n",
       "      <td>...</td>\n",
       "      <td>1.281829</td>\n",
       "      <td>1.203408</td>\n",
       "      <td>2.166338</td>\n",
       "      <td>1.794467</td>\n",
       "      <td>2.302181</td>\n",
       "      <td>0.710622</td>\n",
       "      <td>1.803537</td>\n",
       "      <td>2.134633</td>\n",
       "      <td>2.703053</td>\n",
       "      <td>1.373699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFL</th>\n",
       "      <td>1.684421</td>\n",
       "      <td>1.486982</td>\n",
       "      <td>1.871921</td>\n",
       "      <td>3.177357</td>\n",
       "      <td>1.853532</td>\n",
       "      <td>1.867275</td>\n",
       "      <td>2.748022</td>\n",
       "      <td>1.724180</td>\n",
       "      <td>2.250687</td>\n",
       "      <td>1.557037</td>\n",
       "      <td>...</td>\n",
       "      <td>1.602031</td>\n",
       "      <td>1.356339</td>\n",
       "      <td>2.824852</td>\n",
       "      <td>1.784502</td>\n",
       "      <td>2.535201</td>\n",
       "      <td>0.807126</td>\n",
       "      <td>1.466890</td>\n",
       "      <td>2.139662</td>\n",
       "      <td>2.639058</td>\n",
       "      <td>1.657266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIZ</th>\n",
       "      <td>1.371195</td>\n",
       "      <td>1.222238</td>\n",
       "      <td>1.481065</td>\n",
       "      <td>1.853532</td>\n",
       "      <td>2.697303</td>\n",
       "      <td>1.558646</td>\n",
       "      <td>2.220862</td>\n",
       "      <td>1.375284</td>\n",
       "      <td>1.645819</td>\n",
       "      <td>1.381003</td>\n",
       "      <td>...</td>\n",
       "      <td>1.517803</td>\n",
       "      <td>1.045060</td>\n",
       "      <td>2.222543</td>\n",
       "      <td>1.342421</td>\n",
       "      <td>1.839300</td>\n",
       "      <td>0.711301</td>\n",
       "      <td>1.158381</td>\n",
       "      <td>1.659673</td>\n",
       "      <td>1.819391</td>\n",
       "      <td>1.269354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VZ</th>\n",
       "      <td>0.676519</td>\n",
       "      <td>0.740185</td>\n",
       "      <td>0.710622</td>\n",
       "      <td>0.807126</td>\n",
       "      <td>0.711301</td>\n",
       "      <td>0.739261</td>\n",
       "      <td>1.031245</td>\n",
       "      <td>0.705162</td>\n",
       "      <td>0.778237</td>\n",
       "      <td>0.646654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712041</td>\n",
       "      <td>0.592556</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.699577</td>\n",
       "      <td>0.857685</td>\n",
       "      <td>1.225971</td>\n",
       "      <td>0.656120</td>\n",
       "      <td>0.860807</td>\n",
       "      <td>0.743175</td>\n",
       "      <td>0.684932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WAT</th>\n",
       "      <td>1.468850</td>\n",
       "      <td>1.251271</td>\n",
       "      <td>1.803537</td>\n",
       "      <td>1.466890</td>\n",
       "      <td>1.158381</td>\n",
       "      <td>1.683953</td>\n",
       "      <td>1.967371</td>\n",
       "      <td>1.496761</td>\n",
       "      <td>1.530997</td>\n",
       "      <td>1.188938</td>\n",
       "      <td>...</td>\n",
       "      <td>1.054110</td>\n",
       "      <td>0.852644</td>\n",
       "      <td>1.724189</td>\n",
       "      <td>1.362220</td>\n",
       "      <td>1.751098</td>\n",
       "      <td>0.656120</td>\n",
       "      <td>2.696820</td>\n",
       "      <td>1.654728</td>\n",
       "      <td>1.845218</td>\n",
       "      <td>1.157943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WY</th>\n",
       "      <td>1.935924</td>\n",
       "      <td>1.648574</td>\n",
       "      <td>2.134633</td>\n",
       "      <td>2.139662</td>\n",
       "      <td>1.659673</td>\n",
       "      <td>2.170542</td>\n",
       "      <td>2.824339</td>\n",
       "      <td>1.863104</td>\n",
       "      <td>2.232854</td>\n",
       "      <td>1.879340</td>\n",
       "      <td>...</td>\n",
       "      <td>1.613849</td>\n",
       "      <td>1.324902</td>\n",
       "      <td>2.625611</td>\n",
       "      <td>1.916697</td>\n",
       "      <td>2.491496</td>\n",
       "      <td>0.860807</td>\n",
       "      <td>1.654728</td>\n",
       "      <td>4.020034</td>\n",
       "      <td>2.706502</td>\n",
       "      <td>1.719453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WYNN</th>\n",
       "      <td>2.466527</td>\n",
       "      <td>1.688536</td>\n",
       "      <td>2.703053</td>\n",
       "      <td>2.639058</td>\n",
       "      <td>1.819391</td>\n",
       "      <td>2.853131</td>\n",
       "      <td>3.171963</td>\n",
       "      <td>2.251910</td>\n",
       "      <td>2.812598</td>\n",
       "      <td>2.111700</td>\n",
       "      <td>...</td>\n",
       "      <td>1.732441</td>\n",
       "      <td>1.625497</td>\n",
       "      <td>3.208270</td>\n",
       "      <td>2.353446</td>\n",
       "      <td>3.410284</td>\n",
       "      <td>0.743175</td>\n",
       "      <td>1.845218</td>\n",
       "      <td>2.706502</td>\n",
       "      <td>8.654118</td>\n",
       "      <td>2.135687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XOM</th>\n",
       "      <td>1.371915</td>\n",
       "      <td>1.187972</td>\n",
       "      <td>1.373699</td>\n",
       "      <td>1.657266</td>\n",
       "      <td>1.269354</td>\n",
       "      <td>1.507458</td>\n",
       "      <td>2.025230</td>\n",
       "      <td>1.321276</td>\n",
       "      <td>1.629780</td>\n",
       "      <td>1.181507</td>\n",
       "      <td>...</td>\n",
       "      <td>1.209056</td>\n",
       "      <td>1.016613</td>\n",
       "      <td>2.104366</td>\n",
       "      <td>1.421756</td>\n",
       "      <td>2.296571</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>1.157943</td>\n",
       "      <td>1.719453</td>\n",
       "      <td>2.135687</td>\n",
       "      <td>2.249060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker       ADI       ADP      ADSK       AFL       AIZ      AMAT       AMP  \\\n",
       "ticker                                                                         \n",
       "ADI     3.262099  1.431482  2.258351  1.684421  1.371195  2.754325  2.335061   \n",
       "ADP     1.431482  1.895913  1.649152  1.486982  1.222238  1.645976  1.957046   \n",
       "ADSK    2.258351  1.649152  5.128014  1.871921  1.481065  2.670058  2.705062   \n",
       "AFL     1.684421  1.486982  1.871921  3.177357  1.853532  1.867275  2.748022   \n",
       "AIZ     1.371195  1.222238  1.481065  1.853532  2.697303  1.558646  2.220862   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "VZ      0.676519  0.740185  0.710622  0.807126  0.711301  0.739261  1.031245   \n",
       "WAT     1.468850  1.251271  1.803537  1.466890  1.158381  1.683953  1.967371   \n",
       "WY      1.935924  1.648574  2.134633  2.139662  1.659673  2.170542  2.824339   \n",
       "WYNN    2.466527  1.688536  2.703053  2.639058  1.819391  2.853131  3.171963   \n",
       "XOM     1.371915  1.187972  1.373699  1.657266  1.269354  1.507458  2.025230   \n",
       "\n",
       "ticker       APH       AXP       BBY  ...       TRV       TSN       UNM  \\\n",
       "ticker                                ...                                 \n",
       "ADI     1.830164  1.806743  1.582277  ...  1.230018  1.088972  2.044468   \n",
       "ADP     1.361792  1.552912  1.236547  ...  1.211896  0.922177  1.752877   \n",
       "ADSK    2.045397  1.964669  1.799203  ...  1.281829  1.203408  2.166338   \n",
       "AFL     1.724180  2.250687  1.557037  ...  1.602031  1.356339  2.824852   \n",
       "AIZ     1.375284  1.645819  1.381003  ...  1.517803  1.045060  2.222543   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "VZ      0.705162  0.778237  0.646654  ...  0.712041  0.592556  0.926829   \n",
       "WAT     1.496761  1.530997  1.188938  ...  1.054110  0.852644  1.724189   \n",
       "WY      1.863104  2.232854  1.879340  ...  1.613849  1.324902  2.625611   \n",
       "WYNN    2.251910  2.812598  2.111700  ...  1.732441  1.625497  3.208270   \n",
       "XOM     1.321276  1.629780  1.181507  ...  1.209056  1.016613  2.104366   \n",
       "\n",
       "ticker       VFC       VLO        VZ       WAT        WY      WYNN       XOM  \n",
       "ticker                                                                        \n",
       "ADI     1.533855  1.971979  0.676519  1.468850  1.935924  2.466527  1.371915  \n",
       "ADP     1.327340  1.684646  0.740185  1.251271  1.648574  1.688536  1.187972  \n",
       "ADSK    1.794467  2.302181  0.710622  1.803537  2.134633  2.703053  1.373699  \n",
       "AFL     1.784502  2.535201  0.807126  1.466890  2.139662  2.639058  1.657266  \n",
       "AIZ     1.342421  1.839300  0.711301  1.158381  1.659673  1.819391  1.269354  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "VZ      0.699577  0.857685  1.225971  0.656120  0.860807  0.743175  0.684932  \n",
       "WAT     1.362220  1.751098  0.656120  2.696820  1.654728  1.845218  1.157943  \n",
       "WY      1.916697  2.491496  0.860807  1.654728  4.020034  2.706502  1.719453  \n",
       "WYNN    2.353446  3.410284  0.743175  1.845218  2.706502  8.654118  2.135687  \n",
       "XOM     1.421756  2.296571  0.684932  1.157943  1.719453  2.135687  2.249060  \n",
       "\n",
       "[100 rows x 100 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Covariance Matrix\n",
    "covariance_matrix = returns.cov()\n",
    "covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ticker</th>\n",
       "      <th>ADI</th>\n",
       "      <th>ADP</th>\n",
       "      <th>ADSK</th>\n",
       "      <th>AFL</th>\n",
       "      <th>AIZ</th>\n",
       "      <th>AMAT</th>\n",
       "      <th>AMP</th>\n",
       "      <th>APH</th>\n",
       "      <th>AXP</th>\n",
       "      <th>BBY</th>\n",
       "      <th>...</th>\n",
       "      <th>TRV</th>\n",
       "      <th>TSN</th>\n",
       "      <th>UNM</th>\n",
       "      <th>VFC</th>\n",
       "      <th>VLO</th>\n",
       "      <th>VZ</th>\n",
       "      <th>WAT</th>\n",
       "      <th>WY</th>\n",
       "      <th>WYNN</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "      <td>2769.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.082171</td>\n",
       "      <td>0.075467</td>\n",
       "      <td>0.115515</td>\n",
       "      <td>0.049235</td>\n",
       "      <td>0.077092</td>\n",
       "      <td>0.096573</td>\n",
       "      <td>0.091032</td>\n",
       "      <td>0.078342</td>\n",
       "      <td>0.062060</td>\n",
       "      <td>0.076931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057306</td>\n",
       "      <td>0.082338</td>\n",
       "      <td>0.039803</td>\n",
       "      <td>0.083894</td>\n",
       "      <td>0.090240</td>\n",
       "      <td>0.047957</td>\n",
       "      <td>0.063519</td>\n",
       "      <td>0.059052</td>\n",
       "      <td>0.082285</td>\n",
       "      <td>0.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.806128</td>\n",
       "      <td>1.376921</td>\n",
       "      <td>2.264512</td>\n",
       "      <td>1.782514</td>\n",
       "      <td>1.642347</td>\n",
       "      <td>2.135688</td>\n",
       "      <td>2.168156</td>\n",
       "      <td>1.589992</td>\n",
       "      <td>1.829424</td>\n",
       "      <td>2.523674</td>\n",
       "      <td>...</td>\n",
       "      <td>1.409776</td>\n",
       "      <td>1.844263</td>\n",
       "      <td>2.187580</td>\n",
       "      <td>1.823818</td>\n",
       "      <td>2.497278</td>\n",
       "      <td>1.107236</td>\n",
       "      <td>1.642200</td>\n",
       "      <td>2.005002</td>\n",
       "      <td>2.941788</td>\n",
       "      <td>1.499687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-16.614900</td>\n",
       "      <td>-15.252600</td>\n",
       "      <td>-15.859900</td>\n",
       "      <td>-16.431200</td>\n",
       "      <td>-19.736000</td>\n",
       "      <td>-20.357600</td>\n",
       "      <td>-23.822100</td>\n",
       "      <td>-13.831700</td>\n",
       "      <td>-14.818700</td>\n",
       "      <td>-28.586600</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.800400</td>\n",
       "      <td>-14.489300</td>\n",
       "      <td>-22.368400</td>\n",
       "      <td>-12.921700</td>\n",
       "      <td>-19.220900</td>\n",
       "      <td>-6.620500</td>\n",
       "      <td>-12.313300</td>\n",
       "      <td>-22.673400</td>\n",
       "      <td>-24.434600</td>\n",
       "      <td>-12.224800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.768800</td>\n",
       "      <td>-0.518300</td>\n",
       "      <td>-0.958600</td>\n",
       "      <td>-0.654700</td>\n",
       "      <td>-0.679300</td>\n",
       "      <td>-0.956700</td>\n",
       "      <td>-0.854800</td>\n",
       "      <td>-0.624000</td>\n",
       "      <td>-0.642600</td>\n",
       "      <td>-1.036300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.553600</td>\n",
       "      <td>-0.770300</td>\n",
       "      <td>-0.813000</td>\n",
       "      <td>-0.692300</td>\n",
       "      <td>-1.109900</td>\n",
       "      <td>-0.570000</td>\n",
       "      <td>-0.659100</td>\n",
       "      <td>-0.860100</td>\n",
       "      <td>-1.270700</td>\n",
       "      <td>-0.661600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.075900</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.132600</td>\n",
       "      <td>0.092500</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.079900</td>\n",
       "      <td>0.107700</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.074100</td>\n",
       "      <td>0.098300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.137600</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.091300</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.098800</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.011500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.974800</td>\n",
       "      <td>0.744600</td>\n",
       "      <td>1.220500</td>\n",
       "      <td>0.762600</td>\n",
       "      <td>0.885200</td>\n",
       "      <td>1.208300</td>\n",
       "      <td>1.087200</td>\n",
       "      <td>0.808900</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>1.328900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.708000</td>\n",
       "      <td>0.987300</td>\n",
       "      <td>1.032900</td>\n",
       "      <td>0.951000</td>\n",
       "      <td>1.325100</td>\n",
       "      <td>0.650300</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>1.004100</td>\n",
       "      <td>1.371200</td>\n",
       "      <td>0.699600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.697800</td>\n",
       "      <td>11.803600</td>\n",
       "      <td>16.198500</td>\n",
       "      <td>26.176600</td>\n",
       "      <td>14.148400</td>\n",
       "      <td>13.812200</td>\n",
       "      <td>22.635800</td>\n",
       "      <td>14.758600</td>\n",
       "      <td>21.882300</td>\n",
       "      <td>21.479600</td>\n",
       "      <td>...</td>\n",
       "      <td>13.290300</td>\n",
       "      <td>22.702600</td>\n",
       "      <td>26.204200</td>\n",
       "      <td>14.003000</td>\n",
       "      <td>31.202500</td>\n",
       "      <td>7.680200</td>\n",
       "      <td>12.692700</td>\n",
       "      <td>25.315500</td>\n",
       "      <td>27.688300</td>\n",
       "      <td>12.686800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ticker          ADI          ADP         ADSK          AFL          AIZ  \\\n",
       "count   2769.000000  2769.000000  2769.000000  2769.000000  2769.000000   \n",
       "mean       0.082171     0.075467     0.115515     0.049235     0.077092   \n",
       "std        1.806128     1.376921     2.264512     1.782514     1.642347   \n",
       "min      -16.614900   -15.252600   -15.859900   -16.431200   -19.736000   \n",
       "25%       -0.768800    -0.518300    -0.958600    -0.654700    -0.679300   \n",
       "50%        0.075900     0.094800     0.132600     0.092500     0.100900   \n",
       "75%        0.974800     0.744600     1.220500     0.762600     0.885200   \n",
       "max       14.697800    11.803600    16.198500    26.176600    14.148400   \n",
       "\n",
       "ticker         AMAT          AMP          APH          AXP          BBY  ...  \\\n",
       "count   2769.000000  2769.000000  2769.000000  2769.000000  2769.000000  ...   \n",
       "mean       0.096573     0.091032     0.078342     0.062060     0.076931  ...   \n",
       "std        2.135688     2.168156     1.589992     1.829424     2.523674  ...   \n",
       "min      -20.357600   -23.822100   -13.831700   -14.818700   -28.586600  ...   \n",
       "25%       -0.956700    -0.854800    -0.624000    -0.642600    -1.036300  ...   \n",
       "50%        0.079900     0.107700     0.087600     0.074100     0.098300  ...   \n",
       "75%        1.208300     1.087200     0.808900     0.864100     1.328900  ...   \n",
       "max       13.812200    22.635800    14.758600    21.882300    21.479600  ...   \n",
       "\n",
       "ticker          TRV          TSN          UNM          VFC          VLO  \\\n",
       "count   2769.000000  2769.000000  2769.000000  2769.000000  2769.000000   \n",
       "mean       0.057306     0.082338     0.039803     0.083894     0.090240   \n",
       "std        1.409776     1.844263     2.187580     1.823818     2.497278   \n",
       "min      -20.800400   -14.489300   -22.368400   -12.921700   -19.220900   \n",
       "25%       -0.553600    -0.770300    -0.813000    -0.692300    -1.109900   \n",
       "50%        0.091300     0.137600     0.082800     0.091300     0.086200   \n",
       "75%        0.708000     0.987300     1.032900     0.951000     1.325100   \n",
       "max       13.290300    22.702600    26.204200    14.003000    31.202500   \n",
       "\n",
       "ticker           VZ          WAT           WY         WYNN          XOM  \n",
       "count   2769.000000  2769.000000  2769.000000  2769.000000  2769.000000  \n",
       "mean       0.047957     0.063519     0.059052     0.082285     0.007568  \n",
       "std        1.107236     1.642200     2.005002     2.941788     1.499687  \n",
       "min       -6.620500   -12.313300   -22.673400   -24.434600   -12.224800  \n",
       "25%       -0.570000    -0.659100    -0.860100    -1.270700    -0.661600  \n",
       "50%        0.066800     0.098800     0.069700    -0.009000    -0.011500  \n",
       "75%        0.650300     0.832000     1.004100     1.371200     0.699600  \n",
       "max        7.680200    12.692700    25.315500    27.688300    12.686800  \n",
       "\n",
       "[8 rows x 100 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "returns_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker\n",
       "ADI     20.707110\n",
       "ADP     19.017709\n",
       "ADSK    29.109750\n",
       "AFL     12.407273\n",
       "AIZ     19.427180\n",
       "          ...    \n",
       "VZ      12.085243\n",
       "WAT     16.006814\n",
       "WY      14.881151\n",
       "WYNN    20.735841\n",
       "XOM      1.907246\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annualized_mean_returns = returns.mean() * 252\n",
    "annualized_mean_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticker\n",
       "ADI     28.671394\n",
       "ADP     21.857950\n",
       "ADSK    35.948012\n",
       "AFL     28.296536\n",
       "AIZ     26.071447\n",
       "          ...    \n",
       "VZ      17.576825\n",
       "WAT     26.069115\n",
       "WY      31.828424\n",
       "WYNN    46.699441\n",
       "XOM     23.806789\n",
       "Length: 100, dtype: float64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annualized_std_dev = returns.std() * np.sqrt(252)\n",
    "annualized_std_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portfolio Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns = returns.copy()\n",
    "returns = returns.T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def portfolio_return(weights, returns):\n",
    "    return np.sum(np.mean(returns, axis=1) * weights) * 252\n",
    "\n",
    "def portfolio_volatility(weights, returns):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(np.cov(returns) * 252, weights)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpe_taget(weights, *args):\n",
    "    # get the asset's returns \n",
    "    returns = args[0]\n",
    "\n",
    "    #print(portfolio_return(weights, returns))\n",
    "    #print(portfolio_volatility(weights, returns))\n",
    "    return - portfolio_return(weights, returns) / portfolio_volatility(weights, returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq', \n",
    "         'fun': lambda weights: np.sum(weights) - 1\n",
    "         })\n",
    "\n",
    "bounds = tuple((0, 1) for x in range(len(returns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "equally_weighted_portfolio = np.array([1 / len(returns) for x in range(len(returns))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.855625961255147"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharpe_taget(equally_weighted_portfolio, returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.7 s, sys: 2.04 s, total: 31.7 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opts = minimizer.minimize(sharpe_taget, x0=equally_weighted_portfolio, args=returns, method=\"SLSQP\", bounds=bounds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " message: Optimization terminated successfully\n",
       " success: True\n",
       "  status: 0\n",
       "     fun: -1.462405078312244\n",
       "       x: [ 0.000e+00  8.181e-16 ...  0.000e+00  0.000e+00]\n",
       "     nit: 11\n",
       "     jac: [ 3.425e-01  2.774e-01 ...  5.054e-01  1.138e+00]\n",
       "    nfev: 1113\n",
       "    njev: 11"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_portfolio = opts['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taget_fun(weights, *args):\n",
    "    # get the asset's returns \n",
    "    returns = args[0]\n",
    "\n",
    "    return portfolio_volatility(weights, returns)\n",
    "\n",
    "# specify target level of return \n",
    "return_target = portfolio_return(equally_weighted_portfolio, returns)\n",
    "\n",
    "# the first equality constraint makes sure that the weights of the single assets sum to 1 for the total portfolio\n",
    "# the second constraint fixes the return level which the total portfolio should achieve\n",
    "cons = ({'type': 'eq', \n",
    "         'fun': lambda x: np.sum(np.mean(returns, axis=1) * x) * 252 - return_target\n",
    "         },\n",
    "         {\n",
    "         'type': 'eq', \n",
    "         'fun': lambda x: np.sum(x) - 1\n",
    "         \n",
    "         })\n",
    "\n",
    "bounds = tuple((0, 1) for x in range(len(returns)))\n",
    "\n",
    "equally_weighted_portfolio = np.array([1 / len(returns) for x in range(len(returns))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.6 s, sys: 13 s, total: 55.6 s\n",
      "Wall time: 6.12 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "opts = minimizer.minimize(taget_fun, x0=equally_weighted_portfolio, args=returns, method=\"SLSQP\", bounds=bounds, constraints=cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34148724e-14, 5.84017068e-15, 5.95029074e-14, 8.52886068e-14,\n",
       "       6.33527344e-14, 1.05705170e-13, 4.51091706e-13, 1.35413129e-14,\n",
       "       3.85220657e-15, 1.59618672e-14, 5.06240563e-02, 5.20289233e-02,\n",
       "       8.21926101e-15, 3.46854036e-14, 3.10221117e-02, 4.64475657e-14,\n",
       "       2.88420690e-14, 1.64885874e-01, 3.62529793e-14, 4.73090075e-14,\n",
       "       1.17873838e-01, 4.07366394e-14, 1.60770685e-14, 1.16037449e-14,\n",
       "       4.30976784e-14, 1.98823387e-03, 1.22466203e-13, 5.34487359e-14,\n",
       "       1.23702768e-02, 5.05908877e-14, 7.21844661e-14, 5.91717515e-14,\n",
       "       5.06993510e-15, 4.82772118e-14, 7.52493298e-14, 8.56601209e-04,\n",
       "       8.97970193e-15, 4.50298780e-15, 2.41792597e-13, 1.20298377e-13,\n",
       "       7.95620153e-03, 2.12180855e-14, 5.26396758e-02, 1.94315486e-14,\n",
       "       7.53059740e-15, 2.34132276e-13, 1.69284133e-13, 2.43002600e-14,\n",
       "       7.67049102e-14, 3.71499546e-14, 6.26970223e-13, 8.27264163e-02,\n",
       "       2.24817564e-02, 1.14217592e-13, 4.25398961e-14, 1.20423038e-13,\n",
       "       5.70775640e-02, 8.83407998e-14, 3.32159327e-14, 2.81845568e-13,\n",
       "       1.40216779e-13, 7.64988105e-14, 4.75550913e-14, 4.15288138e-02,\n",
       "       2.45714014e-14, 4.00828949e-14, 7.23463028e-14, 1.90123691e-13,\n",
       "       6.01313040e-14, 1.96147670e-14, 5.23708948e-15, 9.15582048e-14,\n",
       "       8.75320570e-14, 1.22495225e-14, 6.11697844e-14, 8.57030212e-14,\n",
       "       3.66178262e-13, 4.11723702e-03, 1.57161938e-14, 3.58522895e-14,\n",
       "       5.32839899e-02, 4.25611668e-14, 6.08506851e-15, 6.46676559e-02,\n",
       "       7.16735370e-14, 1.09508484e-13, 5.25448590e-14, 9.46945807e-15,\n",
       "       2.35935996e-02, 4.20090858e-14, 5.17436170e-14, 2.96939108e-02,\n",
       "       2.76438958e-13, 2.85744084e-14, 2.45104941e-14, 1.28583263e-01,\n",
       "       1.46444692e-14, 3.19490489e-13, 6.38028740e-14, 6.16575126e-14])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_var_portfolio = opts['x']\n",
    "min_var_portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation Optimal [0.00000000e+00 8.18054587e-16 0.00000000e+00 0.00000000e+00\n",
      " 3.70902588e-15 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 2.51527030e-15 2.74173028e-15\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 3.06940649e-15\n",
      " 0.00000000e+00 1.20725793e-01 1.34137911e-15 4.32305897e-03\n",
      " 2.23780720e-01 8.91824890e-03 1.35559052e-15 0.00000000e+00\n",
      " 1.72775545e-15 6.13672417e-16 0.00000000e+00 2.32207189e-15\n",
      " 2.92851622e-15 1.10598885e-15 2.33153949e-15 8.79769780e-02\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.53516305e-15\n",
      " 0.00000000e+00 4.27416541e-16 0.00000000e+00 0.00000000e+00\n",
      " 2.14865842e-15 0.00000000e+00 9.38690965e-02 0.00000000e+00\n",
      " 5.60176446e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      " 1.19515479e-15 7.37149811e-17 0.00000000e+00 2.70534786e-15\n",
      " 7.31116806e-16 3.17653803e-16 1.64296291e-15 0.00000000e+00\n",
      " 6.48259725e-02 1.76281594e-15 6.18696218e-02 0.00000000e+00\n",
      " 1.41180228e-15 5.19904120e-16 0.00000000e+00 2.55429727e-15\n",
      " 2.93426206e-16 1.36777000e-15 0.00000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 2.86494970e-15\n",
      " 1.79785229e-15 0.00000000e+00 2.47089386e-15 1.23504052e-15\n",
      " 0.00000000e+00 2.57677225e-15 0.00000000e+00 0.00000000e+00\n",
      " 1.87409628e-01 0.00000000e+00 0.00000000e+00 3.96483265e-15\n",
      " 1.88235222e-15 2.57220547e-15 8.51935127e-16 0.00000000e+00\n",
      " 3.02498489e-15 5.54358260e-02 1.41284548e-15 3.48474121e-02\n",
      " 0.00000000e+00 1.93398159e-15 1.58504857e-15 4.43990351e-15\n",
      " 0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "22.681563241331258\n",
      "15.509767832253402\n",
      "Sharpe Ratio 1.46\n"
     ]
    }
   ],
   "source": [
    "print('Allocation Optimal', optimal_portfolio)\n",
    "print(portfolio_return(optimal_portfolio, returns))\n",
    "print(portfolio_volatility(optimal_portfolio, returns))\n",
    "print('Sharpe Ratio', -round(sharpe_taget(optimal_portfolio, returns), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocation Trivial [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01\n",
      " 0.01 0.01]\n",
      "15.931604359696644\n",
      "18.619823475582752\n",
      "Sharpe Ratio 0.86\n"
     ]
    }
   ],
   "source": [
    "print('Allocation Trivial', equally_weighted_portfolio)\n",
    "print(portfolio_return(equally_weighted_portfolio, returns))\n",
    "print(portfolio_volatility(equally_weighted_portfolio, returns))\n",
    "print('Sharpe Ratio', -round(sharpe_taget(equally_weighted_portfolio, returns), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimal variance allocation given target return [1.34148724e-14 5.84017068e-15 5.95029074e-14 8.52886068e-14\n",
      " 6.33527344e-14 1.05705170e-13 4.51091706e-13 1.35413129e-14\n",
      " 3.85220657e-15 1.59618672e-14 5.06240563e-02 5.20289233e-02\n",
      " 8.21926101e-15 3.46854036e-14 3.10221117e-02 4.64475657e-14\n",
      " 2.88420690e-14 1.64885874e-01 3.62529793e-14 4.73090075e-14\n",
      " 1.17873838e-01 4.07366394e-14 1.60770685e-14 1.16037449e-14\n",
      " 4.30976784e-14 1.98823387e-03 1.22466203e-13 5.34487359e-14\n",
      " 1.23702768e-02 5.05908877e-14 7.21844661e-14 5.91717515e-14\n",
      " 5.06993510e-15 4.82772118e-14 7.52493298e-14 8.56601209e-04\n",
      " 8.97970193e-15 4.50298780e-15 2.41792597e-13 1.20298377e-13\n",
      " 7.95620153e-03 2.12180855e-14 5.26396758e-02 1.94315486e-14\n",
      " 7.53059740e-15 2.34132276e-13 1.69284133e-13 2.43002600e-14\n",
      " 7.67049102e-14 3.71499546e-14 6.26970223e-13 8.27264163e-02\n",
      " 2.24817564e-02 1.14217592e-13 4.25398961e-14 1.20423038e-13\n",
      " 5.70775640e-02 8.83407998e-14 3.32159327e-14 2.81845568e-13\n",
      " 1.40216779e-13 7.64988105e-14 4.75550913e-14 4.15288138e-02\n",
      " 2.45714014e-14 4.00828949e-14 7.23463028e-14 1.90123691e-13\n",
      " 6.01313040e-14 1.96147670e-14 5.23708948e-15 9.15582048e-14\n",
      " 8.75320570e-14 1.22495225e-14 6.11697844e-14 8.57030212e-14\n",
      " 3.66178262e-13 4.11723702e-03 1.57161938e-14 3.58522895e-14\n",
      " 5.32839899e-02 4.25611668e-14 6.08506851e-15 6.46676559e-02\n",
      " 7.16735370e-14 1.09508484e-13 5.25448590e-14 9.46945807e-15\n",
      " 2.35935996e-02 4.20090858e-14 5.17436170e-14 2.96939108e-02\n",
      " 2.76438958e-13 2.85744084e-14 2.45104941e-14 1.28583263e-01\n",
      " 1.46444692e-14 3.19490489e-13 6.38028740e-14 6.16575126e-14]\n",
      "15.931604361680499\n",
      "13.020552957763895\n",
      "Sharpe Ratio 1.22\n"
     ]
    }
   ],
   "source": [
    "print('Minimal variance allocation given target return', min_var_portfolio)\n",
    "print(portfolio_return(min_var_portfolio, returns))\n",
    "print(portfolio_volatility(min_var_portfolio, returns))\n",
    "print('Sharpe Ratio', -round(sharpe_taget(min_var_portfolio, returns), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot performance of trivial portfolio vs optiaml portfolio\n",
    "trivial_portfolio = equally_weighted_portfolio\n",
    "markowitz_portfolio = optimal_portfolio\n",
    "min_var_portfolio = min_var_portfolio  # unnecessary\n",
    "\n",
    "df_performance = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
      "/var/folders/z8/18vf272n36z6tx1xm5tv3qvw0000gn/T/ipykernel_30695/2219167502.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n"
     ]
    }
   ],
   "source": [
    "df_performance = pd.DataFrame()\n",
    "df_performance_summary = pd.DataFrame()\n",
    "\n",
    "for i, ticker in enumerate(df_returns):\n",
    "    df_performance['Trivial' + str(ticker)] = trivial_portfolio[i] * df_returns[ticker]\n",
    "    df_performance['Markowitz' + str(ticker)] = markowitz_portfolio[i] * df_returns[ticker]\n",
    "    df_performance['Min Variance' + str(ticker)] = min_var_portfolio[i] * df_returns[ticker]\n",
    "\n",
    "    if i == 0:\n",
    "        df_performance_summary['Trivial'] = df_performance['Trivial' + str(ticker)].copy()\n",
    "        df_performance_summary['Markowitz'] = df_performance['Markowitz' + str(ticker)].copy()\n",
    "        df_performance_summary['Min Variance'] = df_performance['Min Variance' + str(ticker)].copy()\n",
    "    else:\n",
    "        df_performance_summary['Trivial'] = df_performance['Trivial' + str(ticker)] + df_performance_summary['Trivial'].copy()\n",
    "        df_performance_summary['Markowitz'] = df_performance['Markowitz' + str(ticker)] + df_performance_summary['Markowitz'].copy()\n",
    "        df_performance_summary['Min Variance'] = df_performance['Min Variance' + str(ticker)] + df_performance_summary['Min Variance'].copy()\n",
    "\n",
    "df_performance_summary = df_performance_summary.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trivial</th>\n",
       "      <th>Markowitz</th>\n",
       "      <th>Min Variance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1.424721</td>\n",
       "      <td>0.324932</td>\n",
       "      <td>0.481952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1.744349</td>\n",
       "      <td>0.083397</td>\n",
       "      <td>0.243331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>2.006981</td>\n",
       "      <td>0.114824</td>\n",
       "      <td>0.147292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>2.626690</td>\n",
       "      <td>-0.052481</td>\n",
       "      <td>-0.297459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>2.876104</td>\n",
       "      <td>0.331275</td>\n",
       "      <td>-0.229320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-24</th>\n",
       "      <td>174.066288</td>\n",
       "      <td>248.011422</td>\n",
       "      <td>174.287883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-28</th>\n",
       "      <td>174.219570</td>\n",
       "      <td>248.515350</td>\n",
       "      <td>174.469135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-29</th>\n",
       "      <td>173.879635</td>\n",
       "      <td>248.455490</td>\n",
       "      <td>174.325500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-30</th>\n",
       "      <td>174.458205</td>\n",
       "      <td>248.471506</td>\n",
       "      <td>174.229953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31</th>\n",
       "      <td>175.057986</td>\n",
       "      <td>249.227177</td>\n",
       "      <td>175.057986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2769 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Trivial   Markowitz  Min Variance\n",
       "date                                            \n",
       "2010-01-04    1.424721    0.324932      0.481952\n",
       "2010-01-05    1.744349    0.083397      0.243331\n",
       "2010-01-06    2.006981    0.114824      0.147292\n",
       "2010-01-07    2.626690   -0.052481     -0.297459\n",
       "2010-01-08    2.876104    0.331275     -0.229320\n",
       "...                ...         ...           ...\n",
       "2020-12-24  174.066288  248.011422    174.287883\n",
       "2020-12-28  174.219570  248.515350    174.469135\n",
       "2020-12-29  173.879635  248.455490    174.325500\n",
       "2020-12-30  174.458205  248.471506    174.229953\n",
       "2020-12-31  175.057986  249.227177    175.057986\n",
       "\n",
       "[2769 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Trivial', 'Markowitz', 'Min Variance'], dtype='object')"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_performance_summary.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28ddc0750>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(df_performance_summary['Trivial'], label='Equal Weighted Portfolio')\n",
    "plt.plot(df_performance_summary['Markowitz'], label='Mean Variance Optimized Portfolio')\n",
    "plt.plot(df_performance_summary['Min Variance'], label='Minimum Variance Portfolio')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
